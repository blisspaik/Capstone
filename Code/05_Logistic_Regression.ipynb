{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I fit a Logistic Regression model which predicts crime occurrences in Chicago in 2017 based on weather features. I use a pipeline and grid search in order to optimize my hyperparameters and boost my accuracy score. I found that the Logistic Regression model had 58% accuracy for the training data, and 54% for the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing python libraries and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/train.csv')\n",
    "test = pd.read_csv('../Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Assets/columns.pkl', 'rb') as f:\n",
    "    columns = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using 2016 data (train) to predict 2017 data (test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('target', 1)\n",
    "y_train = train[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop('target', 1)\n",
    "y_test = test[['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.96339\n",
       "1.0    0.03661\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.target.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the baseline accuracy for this model is 96.34%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing an easily interpretable model like logistic regression for binary outcomes allows us to make inferences for how a feature impacts the classification probabilities. Additionally, the beta coefficients are easy to interpret compared to other models. In our case, we can use this model to predict whether or not a crime occured in Chicago in 2017 based on weather features. Our negative class represents no crime occurring while our positive class represents a crime occurring.\n",
    "\n",
    "I use pipeline so that I can scale my data and instantiate the model in one step, then use grid search so that I can tune hyperparameters in order to optimize my accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params= {\n",
    "    'lr__penalty': ['l1', 'l2'],\n",
    "    'lr__C': [.001, .01, .03, .05, .75, .9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'lr__penalty': ['l1', 'l2'], 'lr__C': [0.001, 0.01, 0.03, 0.05, 0.75, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = GridSearchCV(pipe, param_grid = params, cv = TimeSeriesSplit(5))\n",
    "LogReg.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value for lr__C that had the highest accuracy score is 0.001\n",
      "The value for lr__penalty that had the highest accuracy score is l1\n"
     ]
    }
   ],
   "source": [
    "for params in LogReg.best_params_:\n",
    "    print('The value for',params,'that had the highest accuracy score is',LogReg.best_params_[params])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These were the best parameters based on grid search. The hyperparameter C represents 1 over alpha, with alpha being the strength of regularization for large coefficients. By having a low C value, we can say that alpha is increasing, resulting in weaker penalization of large coefficients. \n",
    "\n",
    "For the penalty, grid search chose lasso regularization as its optimal parameter. This means that some coefficients will have values of 0, or having no weight. Because a ridge norm would drive down features without eradicating them, we can say that lasso is a more punishing regularization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score of the model is 0.5866628612448054\n",
      "The testing score of the model is 0.5449864854968743\n"
     ]
    }
   ],
   "source": [
    "print('The training score of the model is',LogReg.score(X_train, y_train))\n",
    "print('The testing score of the model is',LogReg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model can accurately predict 58% of all crime occurrences in 2016 (train data). For the crime instances for\n",
    "2017 (test data), the model was able to accurately predict 54% of all instances. The training score has a slightly higher score, indicating slight overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57964856, 0.42035144],\n",
       "       [0.58021103, 0.41978897],\n",
       "       [0.58029136, 0.41970864],\n",
       "       ...,\n",
       "       [0.59007934, 0.40992066],\n",
       "       [0.59015912, 0.40984088],\n",
       "       [0.59023889, 0.40976111]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This probability matrix tells me which class each crime occurence is predicted to be in. For example, the first crime observation in my test dataframe has a 57% chance of being in class 0, meaning that that crime is predicted to not have occurred at that time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29596414, -0.00062126, -0.01306306,  0.        ,  0.09637038,\n",
       "         0.00781081, -0.02868743,  0.        ,  0.        ,  0.00192942,\n",
       "         0.        , -0.02793597,  0.        , -0.0023323 , -0.2286979 ,\n",
       "         0.03376778,  0.        ,  0.        , -0.0003219 ,  0.00232864,\n",
       "         0.05808837,  0.03745805,  0.        , -0.00475741]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_steps = LogReg.best_estimator_.named_steps['lr']\n",
    "named_steps.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_coef_df = pd.DataFrame(named_steps.coef_, columns = columns).T\n",
    "lg_coef_df['coefficients'] = lg_coef_df[0]\n",
    "lg_coef_df.drop(0, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>0.295964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_temp</th>\n",
       "      <td>0.096370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_7_day_avg_Temp</th>\n",
       "      <td>0.058088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_7_day_avg_Daylight</th>\n",
       "      <td>0.037458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunrise</th>\n",
       "      <td>0.033768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_wdsp</th>\n",
       "      <td>0.007811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_7_day_avg_Precip</th>\n",
       "      <td>0.002329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_prcp</th>\n",
       "      <td>0.001929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_7_day_Rain_drizzle</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daylight</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         coefficients\n",
       "hr                           0.295964\n",
       "a_temp                       0.096370\n",
       "prev_7_day_avg_Temp          0.058088\n",
       "prev_7_day_avg_Daylight      0.037458\n",
       "sunrise                      0.033768\n",
       "a_wdsp                       0.007811\n",
       "prev_7_day_avg_Precip        0.002329\n",
       "a_prcp                       0.001929\n",
       "prev_7_day_Rain_drizzle      0.000000\n",
       "daylight                     0.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_coef_df.sort_values(by = 'coefficients', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sorting the weight values in descending order, we can see which features have the highest weights in our model. In other words, these features had the biggest effect in determining whether a crime occurred or not. It seems that hour of the day and average temperature of the day are highly informative in predicting class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_max</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_year</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nighttime</th>\n",
       "      <td>-0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>-0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_thunder</th>\n",
       "      <td>-0.002332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_7_day_Snow</th>\n",
       "      <td>-0.004757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo</th>\n",
       "      <td>-0.013063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_rain_drizzle</th>\n",
       "      <td>-0.027936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_mxpsd</th>\n",
       "      <td>-0.028687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beat_label</th>\n",
       "      <td>-0.228698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 coefficients\n",
       "a_max                0.000000\n",
       "a_year               0.000000\n",
       "nighttime           -0.000322\n",
       "da                  -0.000621\n",
       "a_thunder           -0.002332\n",
       "prev_7_day_Snow     -0.004757\n",
       "mo                  -0.013063\n",
       "a_rain_drizzle      -0.027936\n",
       "a_mxpsd             -0.028687\n",
       "beat_label          -0.228698"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_coef_df.sort_values(by = 'coefficients', ascending = False).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the tail of the dataframe, we can see the features with the lowest weights. Some features have 0 as their coefficient value, resulting from the lasso regularization we implemented in our grid search. To have a negative coefficient means that the probability of crime decreases as that feature's values increase. For example, beat label had the lowest weight in our model with a coefficient value of -0.22. This means that as beat label increases, the probability of crime occurrences decreases. This is not to say that beat areas with higher labels are safer. We can see that there is some correlation, but cannot determine causation without further examining confounding variables such as patrol patterns and how tightly each beat area is clustered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting predictions into confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_test_predictions = LogReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_cm = confusion_matrix(y_test, lg_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted no crime</th>\n",
       "      <th>predicted crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual no crime</th>\n",
       "      <td>1258271</td>\n",
       "      <td>1057086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual crime</th>\n",
       "      <td>36468</td>\n",
       "      <td>51519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predicted no crime  predicted crime\n",
       "actual no crime             1258271          1057086\n",
       "actual crime                  36468            51519"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_cm_df = pd.DataFrame(lg_cm, columns=['predicted no crime', 'predicted crime'], index=['actual no crime', 'actual crime'])\n",
    "lg_cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1258271\n",
      "False Positives: 1057086\n",
      "False Negatives: 36468\n",
      "True Positives: 51519\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, lg_test_predictions).ravel() \n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Crime       0.97      0.54      0.70   2315357\n",
      "       Crime       0.05      0.59      0.09     87987\n",
      "\n",
      "   micro avg       0.54      0.54      0.54   2403344\n",
      "   macro avg       0.51      0.56      0.39   2403344\n",
      "weighted avg       0.94      0.54      0.67   2403344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, LogReg.predict(X_test), target_names=['No Crime', 'Crime']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a high number of false positives, and a relatively low number of false negatives. Having low false negatives means that in comparison to the 3 million rows, only about 36,400 were falsely predicted to not have occurred. The classification report indicates that we have a slightly higher sensitivity score in comparison to specificity. \n",
    "\n",
    "Our model did a good job at correctly predicting true negatives, but when it came to predicting true positives, it was not able to correctly predict as many."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../Data/X_train.csv')\n",
    "X_test.to_csv('../Data/X_test.csv')\n",
    "y_train.to_csv('../Data/y_train.csv')\n",
    "y_test.to_csv('../Data/y_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

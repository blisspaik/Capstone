{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all three models, there was a consistent pattern of low false negatives, and high false positives. Furthermore, when it came to true negatives and true positives, there were more of the former in all models, indicating that more crimes that did not occur were accurately predicted to not occur. When it came to predicting true positives, they were not able to correctly predict more than 65% of true crime occurrences. They were, however, able to minimize the rate of false negatives to about 35-38%, indicating that there were a few crime instances that were not predicted to happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "* Training score: 0.5866\n",
    "* Testing score: 0.5449\n",
    "    \n",
    "**Random Forest**\n",
    "\n",
    "* Training score: 0.9884\n",
    "* Testing score:  0.4318\n",
    "    \n",
    "**Neural Network**\n",
    "\n",
    "* Training score: 0.6437\n",
    "* Testing score:  0.4638"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that logistic regression performed the best in terms of least overfitting. The other two models had high training scores, but low test scores, indicating that they would not perform too well on unseen data. Both models also had similar sensitivity and specificity scores with a giant gap between the two scores. Logistic regression had a slightly higher sensitivity score in comparison to specificity, but only had .05 gap between both scores. As a production model, I would choose logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each model shows good progress by beating the baseline accuracy of 3%. The baseline model, before bootstrapping, guesses randomly for each record weighted by the class balance. So, for each crime record, it would predict crime only 3% of the time. The fact that the model can dramatically beat the baseline accuracy suggests high predictive ability, and is a good start to producing a complex model that predicts crime. \n",
    "\n",
    "Due to the limitation on computing power and length of time for model fitting, the accuracy scores could not be improved at this time. With a bigger machine, we can make dramatically more layers in a neural network, and can allow the model to fit for days. This will allow for more learning ability, and would hopefully result in a higher accuracy score. For logistic regression and random forest, with more time, I hope to tune the hyperparameters so that my model could be optimized to the highest degree. This would take a lot of processing power and time, so again, having a bigger machine with more computing power would allow me to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this time, beat label is a proxy for true geospatial analysis. I did not produce any geospatial models, so beat label was not fully used as strong predictor variable for crime. It merely hinted at a geospatial element in the models. For future models, I would like to explore multiclassification so that I could specify a specific beat label for where a crime occurred. Furthermore, I would like to predict the type of violent crime, whether it be battery, assault, kidnapping, etc, and the time that the crime occured at. I would like to combine geospatial elements, time series elements, and types of crime so that the next model would be able to predict where a certain crime occurred at a certain time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations for Chicago"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This could also mean that more people are out during these months because it is the summer. If this is the case, then I can use my model results to recommend to the city of Chicago certain programs that can keep people inside.\n",
    "- Based on plot in crime notebook, we can see an increase in crime from 2014-2017. This calls for action to be taken by police department.\n",
    "- Talk about arrest countplot and how each crime could be difficult/easy to investigate for police.\n",
    "- maybe should not use beat label as an important feature in this model due to the fact that it seems as beat increases, the probability of crime decreases. (more tightly clustered patrol patterns control crime more effective / this can be biased because as beat # increases, we go more north so Northern Chicago could have more crime (research) / this then goes into race and ethics / police ethics \n",
    "- evaluate police predictive biases in their algorithms / bring in ethics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget gitignore\n",
    "# requirements txt (! pip freeze -> .txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

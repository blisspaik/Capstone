{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Negative Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the crime data only consists of positive instances of crime, there is no negative class. By creating a negative class, I will be able to predict violent crime occurences for 2017 using classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing python libraries and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_2016 = pd.read_csv('../Data/crime_2016.csv', index_col = 0)\n",
    "weather_2016 = pd.read_csv('../Data/weather_2016.csv', index_col = 0)\n",
    "crime_2017 = pd.read_csv('../Data/crime_2017.csv', index_col = 0)\n",
    "weather_2017 = pd.read_csv('../Data/weather_2017.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating hours dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to first create a dataframe containing hours for each day of the year using `timedelta` and `datetime`. The reasoning behind this is so that we can merge the hours dataframe with weather data in order to match the level of granularity that the crime data has. The crime data consists of hourly occurrences, so we need the weather data to also have an hours feature. By merging the hours data with weather data, we are enabling a smooth merge on time features with the crime data. These merged dataframes will then be our final train and test datasets (2016 is train and 2017 is test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    delta = timedelta(hours=1)\n",
    "    while start_date < end_date:\n",
    "        yield start_date\n",
    "        start_date += delta\n",
    "        \n",
    "start_date = datetime(2016, 1, 1, 0, 00)\n",
    "end_date = datetime(2017, 1, 1, 0, 00)\n",
    "dates_list = []\n",
    "for single_date in daterange(start_date, end_date):\n",
    "    dates_list.append(single_date.strftime(\"%Y-%m-%d %H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_df = pd.DataFrame(dates_list, columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hr</th>\n",
       "      <th>da</th>\n",
       "      <th>mo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  hr  da  mo\n",
       "0 2016-01-01 00:00:00   0   1   1\n",
       "1 2016-01-01 01:00:00   1   1   1\n",
       "2 2016-01-01 02:00:00   2   1   1\n",
       "3 2016-01-01 03:00:00   3   1   1\n",
       "4 2016-01-01 04:00:00   4   1   1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hours_df['date'] = pd.to_datetime(hours_df['date'])\n",
    "hours_df['hr'] = hours_df.date.dt.hour\n",
    "hours_df['da'] = hours_df.date.dt.day\n",
    "hours_df['mo'] = hours_df.date.dt.month\n",
    "hours_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging hours dataframe with weater data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_2016 = hours_df.merge(weather_2016, how='left', left_on=['mo', 'da'], right_on=['a_mo', 'a_da'])\n",
    "hourly_weather_2017 = hours_df.merge(weather_2017, how='left', left_on=['mo', 'da'], right_on=['a_mo', 'a_da'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hr</th>\n",
       "      <th>da</th>\n",
       "      <th>mo</th>\n",
       "      <th>a_stn</th>\n",
       "      <th>a_wban</th>\n",
       "      <th>a_year</th>\n",
       "      <th>a_mo</th>\n",
       "      <th>a_da</th>\n",
       "      <th>a_temp</th>\n",
       "      <th>...</th>\n",
       "      <th>b_wban</th>\n",
       "      <th>b_name</th>\n",
       "      <th>b_country</th>\n",
       "      <th>b_state</th>\n",
       "      <th>b_call</th>\n",
       "      <th>b_lat</th>\n",
       "      <th>b_lon</th>\n",
       "      <th>b_elev</th>\n",
       "      <th>b_begin</th>\n",
       "      <th>b_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>725300</td>\n",
       "      <td>94846</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>...</td>\n",
       "      <td>94846</td>\n",
       "      <td>CHICAGO O'HARE INTERNATIONAL</td>\n",
       "      <td>US</td>\n",
       "      <td>IL</td>\n",
       "      <td>KORD</td>\n",
       "      <td>41.995</td>\n",
       "      <td>-87.934</td>\n",
       "      <td>201.8</td>\n",
       "      <td>19461001</td>\n",
       "      <td>20181015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>725300</td>\n",
       "      <td>94846</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>...</td>\n",
       "      <td>94846</td>\n",
       "      <td>CHICAGO O'HARE INTERNATIONAL</td>\n",
       "      <td>US</td>\n",
       "      <td>IL</td>\n",
       "      <td>KORD</td>\n",
       "      <td>41.995</td>\n",
       "      <td>-87.934</td>\n",
       "      <td>201.8</td>\n",
       "      <td>19461001</td>\n",
       "      <td>20181015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>725300</td>\n",
       "      <td>94846</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>...</td>\n",
       "      <td>94846</td>\n",
       "      <td>CHICAGO O'HARE INTERNATIONAL</td>\n",
       "      <td>US</td>\n",
       "      <td>IL</td>\n",
       "      <td>KORD</td>\n",
       "      <td>41.995</td>\n",
       "      <td>-87.934</td>\n",
       "      <td>201.8</td>\n",
       "      <td>19461001</td>\n",
       "      <td>20181015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>725300</td>\n",
       "      <td>94846</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>...</td>\n",
       "      <td>94846</td>\n",
       "      <td>CHICAGO O'HARE INTERNATIONAL</td>\n",
       "      <td>US</td>\n",
       "      <td>IL</td>\n",
       "      <td>KORD</td>\n",
       "      <td>41.995</td>\n",
       "      <td>-87.934</td>\n",
       "      <td>201.8</td>\n",
       "      <td>19461001</td>\n",
       "      <td>20181015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>725300</td>\n",
       "      <td>94846</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>...</td>\n",
       "      <td>94846</td>\n",
       "      <td>CHICAGO O'HARE INTERNATIONAL</td>\n",
       "      <td>US</td>\n",
       "      <td>IL</td>\n",
       "      <td>KORD</td>\n",
       "      <td>41.995</td>\n",
       "      <td>-87.934</td>\n",
       "      <td>201.8</td>\n",
       "      <td>19461001</td>\n",
       "      <td>20181015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  hr  da  mo   a_stn  a_wban  a_year  a_mo  a_da  a_temp  \\\n",
       "0 2016-01-01 00:00:00   0   1   1  725300   94846    2016     1     1    23.4   \n",
       "1 2016-01-01 01:00:00   1   1   1  725300   94846    2016     1     1    23.4   \n",
       "2 2016-01-01 02:00:00   2   1   1  725300   94846    2016     1     1    23.4   \n",
       "3 2016-01-01 03:00:00   3   1   1  725300   94846    2016     1     1    23.4   \n",
       "4 2016-01-01 04:00:00   4   1   1  725300   94846    2016     1     1    23.4   \n",
       "\n",
       "     ...     b_wban                        b_name  b_country  b_state  b_call  \\\n",
       "0    ...      94846  CHICAGO O'HARE INTERNATIONAL         US       IL    KORD   \n",
       "1    ...      94846  CHICAGO O'HARE INTERNATIONAL         US       IL    KORD   \n",
       "2    ...      94846  CHICAGO O'HARE INTERNATIONAL         US       IL    KORD   \n",
       "3    ...      94846  CHICAGO O'HARE INTERNATIONAL         US       IL    KORD   \n",
       "4    ...      94846  CHICAGO O'HARE INTERNATIONAL         US       IL    KORD   \n",
       "\n",
       "    b_lat   b_lon  b_elev   b_begin     b_end  \n",
       "0  41.995 -87.934   201.8  19461001  20181015  \n",
       "1  41.995 -87.934   201.8  19461001  20181015  \n",
       "2  41.995 -87.934   201.8  19461001  20181015  \n",
       "3  41.995 -87.934   201.8  19461001  20181015  \n",
       "4  41.995 -87.934   201.8  19461001  20181015  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have weather values for each hour of 2016, we can add beat label as a new column. By doing so, we are ensuring that the correct beat label corresponds to the right crime value for a given hour when merging. The features that will be merged on are month, day, hour, and beat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding beat label to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/blisspaik/notebooks/DSI-US-5/capstone/Data/cumulative-train.csv'\n",
    "with open(filename, 'w') as f: \n",
    "    writer = csv.writer(f) \n",
    "    header = hourly_weather.columns \n",
    "    writer.writerow(header)\n",
    "    \n",
    "for beat_label in crime.beat.value_counts().index:\n",
    "    hourly_weather['beat_label'] = beat_label\n",
    "    hourly_weather.to_csv(filename, mode = 'a', index=False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this function is doing is opening a direct filepath in write mode to the csv so that a column could be easily added. We can then read in the new dataframe with the added beat column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../Data/cumulative-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2406816, 18)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do the same for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/blisspaik/notebooks/DSI-US-5/capstone/Data/cumulative-test.csv'\n",
    "with open(filename, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # write the header \n",
    "    header = hourly_weather.columns\n",
    "    writer.writerow(header)\n",
    "    \n",
    "for beat_label in crime.beat.value_counts().index:\n",
    "    hourly_weather['beat_label'] = beat_label\n",
    "    hourly_weather.to_csv(filename, mode = 'a', index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../Data/cumulative-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400240, 18)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging crime and weather dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make a target column for crime data filled with 1's so that when it is merged, we can see either 1's or NaN's. The NaN's represent rows where crime did not occur at that given time. These nulls could then be replaced with 0's, resulting in our negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_2016['target'] = 1\n",
    "crime_2017['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.merge(crime_2016[['beat', 'a_mo', 'a_da', 'a_hour', 'target']], how='left', left_on=['beat_label', 'mo', 'da', 'hr'], \n",
    "                       right_on=['beat', 'a_mo', 'a_da', 'a_hour'])\n",
    "test_df = test_df.merge(crime_2017[['beat', 'a_mo', 'a_da', 'a_hour', 'target']], how='left', left_on=['beat_label', 'mo', 'da', 'hr'], \n",
    "                       right_on=['beat', 'a_mo', 'a_da', 'a_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2410013, 17), (2403351, 17))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]:\n",
    "    df.drop(['beat', 'a_mo_x', 'a_da_x', 'a_mo_y', 'a_da_y', 'a_hour'], 1, inplace=True)\n",
    "    df.sort_values(['a_year', 'mo', 'da', 'hr', 'beat_label'], inplace=True)\n",
    "    df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dropped all columns that were duplicated in the merge, and replaced all nulls with 0's. Now that we have both classes, we are one step closer to modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../Data/train_df.csv')\n",
    "test_df.to_csv('../Data/test_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
